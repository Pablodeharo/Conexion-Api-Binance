{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ccxt\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from binance.client import Client\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import GRU, LSTM, Dense, Dropout, Input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tqdm import tqdm\n",
    "import talib as ta\n",
    "import ta\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()  # Esto carga las variables de entorno desde `.env`\n",
    "\n",
    "api_key = os.getenv('API_KEY')\n",
    "api_secret = os.getenv('API_SECRET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for BTCUSDT at interval 1h\n",
      "Data fetched and saved for BTCUSDT at interval 1h. Data shape: (59040, 5)\n",
      "Fetching data for ETHUSDT at interval 1h\n",
      "Data fetched and saved for ETHUSDT at interval 1h. Data shape: (59040, 5)\n",
      "Fetching data for XRPUSDT at interval 1h\n",
      "Data fetched and saved for XRPUSDT at interval 1h. Data shape: (52836, 5)\n",
      "Fetching data for LTCUSDT at interval 1h\n",
      "Data fetched and saved for LTCUSDT at interval 1h. Data shape: (56215, 5)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Conexión a la base de datos con los datos sacados en tiempo real\n",
    "conn_realtime = sqlite3.connect(r'C:\\Users\\lenovo\\Desktop\\Conexion Api Binance\\crypto_data.db')\n",
    "\n",
    "# Consulta SQL para obtener los datos en tiempo real\n",
    "# Ajusta el nombre de la tabla según corresponda\n",
    "query_realtime = \"SELECT * FROM btcusdt_1h_data\"\n",
    "\n",
    "# Ejecutar la consulta y guardar los resultados en un DataFrame\n",
    "df_realtime = pd.read_sql_query(query_realtime, conn_realtime)\n",
    "\n",
    "# Cerrar la conexión a la base de datos en tiempo real\n",
    "conn_realtime.close()\n",
    "\n",
    "# Cliente de Binance\n",
    "client = Client(api_key, api_secret)\n",
    "\n",
    "def fetch_binance_data(symbol, interval, limit=1000):\n",
    "    bars = client.get_historical_klines(symbol, interval, \"1 Jan, 2017\", limit=limit)\n",
    "    df = pd.DataFrame(bars, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_av', 'trades', 'tb_base_av', 'tb_quote_av', 'ignore'])\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "    df = df[['open', 'high', 'low', 'close', 'volume']]\n",
    "    return df\n",
    "\n",
    "symbols = ['BTCUSDT', 'ETHUSDT', 'XRPUSDT', 'LTCUSDT']\n",
    "intervals = ['1h']  # Solo intervalos horarios\n",
    "\n",
    "data = {}  # Diccionario para almacenar DataFrames\n",
    "raw_data_dir = \"../data/raw\"\n",
    "os.makedirs(raw_data_dir, exist_ok=True)\n",
    "\n",
    "for symbol in symbols:\n",
    "    data[symbol] = {}\n",
    "    for interval in intervals:\n",
    "        try:\n",
    "            print(f\"Fetching data for {symbol} at interval {interval}\")\n",
    "            df = fetch_binance_data(symbol, interval)\n",
    "            data[symbol][interval] = df\n",
    "            # Guardar los datos descargados\n",
    "            df.to_csv(f\"{raw_data_dir}/{symbol}_{interval}.csv\")\n",
    "            print(f\"Data fetched and saved for {symbol} at interval {interval}. Data shape: {df.shape}\")\n",
    "            time.sleep(60)  # Delay para no violar los límites de la API\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {symbol} at interval {interval}: {str(e)}\")\n",
    "\n",
    "# Concatenar los datos históricos con los de tiempo real y renombrar el dataframe\n",
    "df_concatenated = pd.concat([df_realtime, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<string>, line 83)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<string>:83\u001b[1;36m\u001b[0m\n\u001b[1;33m    def add_candle_patterns(self):\u001b[0m\n\u001b[1;37m                                  ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Con los dataframes concatenados pre procesamos los datos y guardamos los datos en un nuevo base de datos sql (crypto_data_proc.db)\n",
    "class CryptoDataProcessor:\n",
    "    def __init__(self, df_concatenated, conn, table_name, symbol):\n",
    "        self.df = df_concatenated\n",
    "        self.conn = conn\n",
    "        self.table_name = table_name\n",
    "        self.symbol = symbol\n",
    "        # Inicialización basada en análisis de puntos extremos iniciales\n",
    "        self.initialize_support_resistance()\n",
    "        self.breakout_threshold = 0.01  # 1% por encima o por debajo\n",
    "\n",
    "    def initialize_support_resistance(self):\n",
    "        # Establecer soporte inicial como el mínimo de los primeros días\n",
    "        self.support = min(self.df[f'{self.symbol}_low'].iloc[:30])\n",
    "        # Establecer resistencia inicial como el máximo de los primeros días\n",
    "        self.resistance = max(self.df[f'{self.symbol}_high'].iloc[:30])\n",
    "        self.df[f'{self.symbol}_support'] = self.support\n",
    "        self.df[f'{self.symbol}_resistance'] = self.resistance\n",
    "\n",
    "    def update_support_resistance(self):\n",
    "        # Crear columnas para soporte y resistencia dinámicos\n",
    "        self.df[f'{self.symbol}_dynamic_support'] = self.support\n",
    "        self.df[f'{self.symbol}_dynamic_resistance'] = self.resistance\n",
    "\n",
    "        for index, row in self.df.iterrows():\n",
    "            current_low = row[f'{self.symbol}_low']\n",
    "            current_high = row[f'{self.symbol}_high']\n",
    "            current_close = row[f'{self.symbol}_close']\n",
    "\n",
    "            # Revisar y ajustar soporte y resistencia\n",
    "            if current_close > self.resistance:\n",
    "                self.support = self.resistance  # La resistencia rota se convierte en soporte\n",
    "                self.resistance = current_high\n",
    "            elif current_close < self.support:\n",
    "                self.resistance = self.support  # El soporte roto se convierte en resistencia\n",
    "                self.support = current_low\n",
    "\n",
    "            # Actualizar el DataFrame con los valores dinámicos\n",
    "            self.df.at[index, f'{self.symbol}_dynamic_support'] = self.support\n",
    "            self.df.at[index, f'{self.symbol}_dynamic_resistance'] = self.resistance         \n",
    "\n",
    "    def add_technical_indicators(self):\n",
    "        # Calcular SMAs y EMAs con manejo inicial dinámico para los datos iniciales limitados\n",
    "        windows = [7, 14, 21, 28, 50, 100, 200]\n",
    "        for i in windows:\n",
    "            self.df[f'{self.symbol}_sma_{i}'] = self.df[f'{self.symbol}_close'].rolling(window=i, min_periods=1).mean()\n",
    "            self.df[f'{self.symbol}_ema_{i}'] = self.df[f'{self.symbol}_close'].ewm(span=i, adjust=False, min_periods=1).mean()\n",
    "\n",
    "        # RSI personalizado\n",
    "        delta = self.df[f'{self.symbol}_close'].diff()\n",
    "        gain = delta.where(delta > 0, 0.0)\n",
    "        loss = -delta.where(delta < 0, 0.0)\n",
    "\n",
    "        # Usar mean() con min_periods=1 asegura que calculamos el valor incluso si hay menos datos que la ventana\n",
    "        avg_gain = gain.rolling(window=14, min_periods=1).mean()\n",
    "        avg_loss = loss.rolling(window=14, min_periods=1).mean()\n",
    "\n",
    "        rs = avg_gain / avg_loss\n",
    "        self.df[f'{self.symbol}_rsi_14'] = 100.0 - (100.0 / (1.0 + rs))\n",
    "\n",
    "        # MACD\n",
    "        macd = ta.trend.MACD(self.df[f'{self.symbol}_close'])\n",
    "        self.df[f'{self.symbol}_macd'] = macd.macd()\n",
    "        self.df[f'{self.symbol}_macd_signal'] = macd.macd_signal()\n",
    "        self.df[f'{self.symbol}_macd_diff'] = macd.macd_diff()\n",
    "\n",
    "        # Williams %R\n",
    "        self.df[f'{self.symbol}_willr'] = ta.momentum.williams_r(\n",
    "            self.df[f'{self.symbol}_high'], self.df[f'{self.symbol}_low'], self.df[f'{self.symbol}_close'], lbp=14)\n",
    "\n",
    "        # ATR\n",
    "        self.df[f'{self.symbol}_atr_14'] = ta.volatility.average_true_range(\n",
    "            self.df[f'{self.symbol}_high'], self.df[f'{self.symbol}_low'], self.df[f'{self.symbol}_close'], window=14)\n",
    "\n",
    "        # ADX\n",
    "        self.df[f'{self.symbol}_adx'] = ta.trend.adx(\n",
    "            self.df[f'{self.symbol}_high'], self.df[f'{self.symbol}_low'], self.df[f'{self.symbol}_close'], window=14)\n",
    "\n",
    "        # Commodity Channel Index\n",
    "        self.df[f'{self.symbol}_cci'] = ta.trend.cci(\n",
    "            self.df[f'{self.symbol}_high'], self.df[f'{self.symbol}_low'], self.df[f'{self.symbol}_close'], window=20)\n",
    " \n",
    " def add_candle_patterns(self):\n",
    "    # Patrones básicos y comunes\n",
    "        self.df[f'{self.symbol}_doji'] = talib.CDLDOJI(\n",
    "        self.df[f'{self.symbol}_open'], self.df[f'{self.symbol}_high'], self.df[f'{self.symbol}_low'], self.df[f'{self.symbol}_close'])\n",
    "        self.df[f'{self.symbol}_engulfing'] = talib.CDLENGULFING(\n",
    "        self.df[f'{self.symbol}_open'], self.df[f'{self.symbol}_high'], self.df[f'{self.symbol}_low'], self.df[f'{self.symbol}_close'])\n",
    "        self.df[f'{self.symbol}_hammer'] = talib.CDLHAMMER(\n",
    "        self.df[f'{self.symbol}_open'], self.df[f'{self.symbol}_high'], self.df[f'{self.symbol}_low'], self.df[f'{self.symbol}_close'])\n",
    "        self.df[f'{self.symbol}_inverted_hammer'] = talib.CDLINVERTEDHAMMER(\n",
    "        self.df[f'{self.symbol}_open'], self.df[f'{self.symbol}_high'], self.df[f'{self.symbol}_low'], self.df[f'{self.symbol}_close'])\n",
    "        self.df[f'{self.symbol}_hanging_man'] = talib.CDLHANGINGMAN(\n",
    "        self.df[f'{self.symbol}_open'], self.df[f'{self.symbol}_high'], self.df[f'{self.symbol}_low'], self.df[f'{self.symbol}_close'])\n",
    "        self.df[f'{self.symbol}_shooting_star'] = talib.CDLSHOOTINGSTAR(\n",
    "        self.df[f'{self.symbol}_open'], self.df[f'{self.symbol}_high'], self.df[f'{self.symbol}_low'], self.df[f'{self.symbol}_close'])\n",
    "        self.df[f'{self.symbol}_morning_star'] = talib.CDLMORNINGSTAR(\n",
    "        self.df[f'{self.symbol}_open'], self.df[f'{self.symbol}_high'], self.df[f'{self.symbol}_low'], self.df[f'{self.symbol}_close'])\n",
    "        self.df[f'{self.symbol}_evening_star'] = talib.CDLEVENINGSTAR(\n",
    "        self.df[f'{self.symbol}_open'], self.df[f'{self.symbol}_high'], self.df[f'{self.symbol}_low'], self.df[f'{self.symbol}_close'])\n",
    "        self.df[f'{self.symbol}_morning_doji_star'] = talib.CDLMORNINGDOJISTAR(\n",
    "        self.df[f'{self.symbol}_open'], self.df[f'{self.symbol}_high'], self.df[f'{self.symbol}_low'], self.df[f'{self.symbol}_close'])\n",
    "        self.df[f'{self.symbol}_evening_doji_star'] = talib.CDLEVENINGDOJISTAR(\n",
    "        self.df[f'{self.symbol}_open'], self.df[f'{self.symbol}_high'], self.df[f'{self.symbol}_low'], self.df[f'{self.symbol}_close'])\n",
    "\n",
    "    # Patrones complejos\n",
    "        self.df[f'{self.symbol}_piercing_line'] = talib.CDLPIERCING(\n",
    "        self.df[f'{self.symbol}_open'], self.df[f'{self.symbol}_high'], self.df[f'{self.symbol}_low'], self.df[f'{self.symbol}_close'])\n",
    "        self.df[f'{self.symbol}_dark_cloud_cover'] = talib.CDLDARKCLOUDCOVER(\n",
    "        self.df[f'{self.symbol}_open'], self.df[f'{self.symbol}_high'], self.df[f'{self.symbol}_low'], self.df[f'{self.symbol}_close'])\n",
    "        self.df[f'{self.symbol}_three_white_soldiers'] = talib.CDL3WHITESOLDIERS(\n",
    "        self.df[f'{self.symbol}_open'], self.df[f'{self.symbol}_high'], self.df[f'{self.symbol}_low'], self.df[f'{self.symbol}_close'])\n",
    "        self.df[f'{self.symbol}_three_black_crows'] = talib.CDL3BLACKCROWS(\n",
    "        self.df[f'{self.symbol}_open'], self.df[f'{self.symbol}_high'], self.df[f'{self.symbol}_low'], self.df[f'{self.symbol}_close'])\n",
    "        self.df[f'{self.symbol}_three_inside_up_down'] = talib.CDL3INSIDE(\n",
    "        self.df[f'{self.symbol}_open'], self.df[f'{self.symbol}_high'], self.df[f'{self.symbol}_low'], self.df[f'{self.symbol}_close'])\n",
    "        self.df[f'{self.symbol}_three_outside_up_down'] = talib.CDL3OUTSIDE(\n",
    "        self.df[f'{self.symbol}_open'], self.df[f'{self.symbol}_high'], self.df[f'{self.symbol}_low'], self.df[f'{self.symbol}_close'])\n",
    "        self.df[f'{self.symbol}_three_stars_in_the_south'] = talib.CDL3STARSINSOUTH(\n",
    "        self.df[f'{self.symbol}_open'], self.df[f'{self.symbol}_high'], self.df[f'{self.symbol}_low'], self.df[f'{self.symbol}_close'])\n",
    "        self.df[f'{self.symbol}_three_advancing_white_soldiers'] = talib.CDL3WHITESOLDIERS(\n",
    "        self.df[f'{self.symbol}_open'], self.df[f'{self.symbol}_high'], self.df[f'{self.symbol}_low'], self.df[f'{self.symbol}_close'])\n",
    "\n",
    "def process(self):\n",
    "        self.initialize_support_resistance()\n",
    "        self.add_technical_indicators()\n",
    "        self.add_candle_patterns()\n",
    "        self.update_support_resistance()\n",
    "        # Añadir el precio de cierre de la siguiente hora como variable a predecir\n",
    "        self.df[f'{self.symbol}_next_close'] = self.df[f'{self.symbol}_close'].shift(-1)\n",
    "        self.df.to_sql(self.table_name, self.conn, if_exists='replace', index=False)\n",
    "\n",
    "# Código para cargar y renombrar los DataFrames correctamente\n",
    "data = {}\n",
    "symbols = ['BTCUSDT', 'ETHUSDT', 'XRPUSDT', 'LTCUSDT']\n",
    "for symbol in symbols:\n",
    "    file_path = f\"{raw_data_dir}/{symbol}_1h.csv\"\n",
    "    if os.path.exists(file_path):\n",
    "        df = pd.read_csv(file_path, index_col='timestamp', parse_dates=True)\n",
    "        # Añadir el prefijo del símbolo a las columnas\n",
    "        df.columns = [f\"{symbol}_{col}\" for col in df.columns]\n",
    "        data[symbol] = df\n",
    "    else:\n",
    "        print(f\"No data file found for {symbol}\")\n",
    "\n",
    "processed_data = {symbol: CryptoDataProcessor(data[symbol], conn_crypto_data_proc, symbol.lower() + '_processed', symbol).process() \n",
    "                  for symbol in data}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar a la base de datos donde se guardarán los datos procesados\n",
    "conn_crypto_data_proc = sqlite3.connect('C:/Users/lenovo/Desktop/Conexion Api Binance/crypto_data_proc.db')\n",
    "\n",
    "# Nombre de la tabla donde se guardarán los datos procesados\n",
    "table_name = 'crypto_data_processed'\n",
    "\n",
    "# Guardar los datos procesados en un nuevo DataFrame\n",
    "processed_data = {}\n",
    "\n",
    "# Después de procesar los datos, iterar sobre los datos para guardarlos en la base de datos\n",
    "for symbol, df in processed_data.items():\n",
    "    # Guardar el DataFrame en la base de datos\n",
    "    df.to_sql(table_name, conn_crypto_data_proc, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql 'SELECT * FROM crypto_data_processed': no such table: crypto_data_processed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\sql.py:2672\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m   2671\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2672\u001b[0m     \u001b[43mcur\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2673\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[1;31mOperationalError\u001b[0m: no such table: crypto_data_processed",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT * FROM crypto_data_processed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Leer los datos de la tabla en un DataFrame\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m df_from_db \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Cerrar la conexión a la base de datos\u001b[39;00m\n\u001b[0;32m     11\u001b[0m conn\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\sql.py:526\u001b[0m, in \u001b[0;36mread_sql_query\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[1;32m--> 526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    529\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    533\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\sql.py:2736\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[1;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[0;32m   2725\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[0;32m   2726\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   2727\u001b[0m     sql,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2734\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2735\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[1;32m-> 2736\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2737\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[0;32m   2739\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\sql.py:2684\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m   2681\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minner_exc\u001b[39;00m\n\u001b[0;32m   2683\u001b[0m ex \u001b[38;5;241m=\u001b[39m DatabaseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2684\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mDatabaseError\u001b[0m: Execution failed on sql 'SELECT * FROM crypto_data_processed': no such table: crypto_data_processed"
     ]
    }
   ],
   "source": [
    "# Conectar a la base de datos\n",
    "conn = sqlite3.connect('C:/Users/lenovo/Desktop/Conexion Api Binance/crypto_data_proc.db')\n",
    "\n",
    "# Realizar una consulta SQL para seleccionar todos los datos de la tabla\n",
    "query = \"SELECT * FROM crypto_data_processed\"\n",
    "\n",
    "# Leer los datos de la tabla en un DataFrame\n",
    "df_from_db = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Cerrar la conexión a la base de datos\n",
    "conn.close()\n",
    "\n",
    "# Imprimir el DataFrame\n",
    "print(df_from_db)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
